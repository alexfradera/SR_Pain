---
title: "Search terms"
author: "Alex Fradera"
date: "15/06/2021"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r launch_scripts, echo=FALSE, fig.show='hide', include=TRUE, warning=FALSE}
# This is the cleaning and pre-processing described above.
# setwd("C:/Users/Alexander Fradera/OneDrive - University of Glasgow/non-dclin/5_Code/SR_Pain/")
 source("SR_functions.R", local = knitr::knit_global(), echo = FALSE)
```


# Litsearchr term identification process

## 1. Conduct naive searches
Complete one or more searches of interest. This should be done in a way that produces a *.nbib file. Eg in PubMed complete your search and then select "Send To" citation manager. Put the saved file in your project folder.

** In my case, 
SEARCH_1 I searched PubMed pain* AND cognit* and screen* which produced 949 results, but realised it included a lot of CBT stuff which was not in focus. I then amended using NOT (cognit* behav* therapy) to limit the irrelevant results (659).**
SEARCH_2 focuses only on pain terms: pain OR fibromyalgia OR migraine OR neuropathic. This produced nearly a million results so I limited to clinical trials and RCTS within the last year (2529 results).
SEARCH_3 for completeness looks at cognitive screen terms: "cognitive screen*" OR "Addenbrooke's Cognitive Examination" OR "Addenbrooke's Cognitive Examination Revised" OR "Mini-ACE" OR "Abbreviated Mental Test" OR "Mini-Cog" OR "Addenbrooke's Cognitive Examination - III" OR "Montreal Cognitive Assessment" OR "Mini Mental State Examination" OR "6-item cognitive impairment test" OR "Hopkins Verbal Learning Test" OR "Hopkins Verbal Learning Test Revised" OR "Test for the early detection of dementia" OR "Severe Impairment battery" OR "AMTS" OR "ACE-3" OR "SIB" OR "ACE" OR "ACE-R" OR "M-ACE" OR "AMT" OR "Mini-Cog" OR "ACE-III" OR "MoCA" OR "MMSE" OR "6CIT" OR "HVLT" OR "HVLT-R" OR "TE4D-Cog" OR "SiB7" (1132 results)

You then pull these searches into R

```{r pull_bib-files, echo=TRUE}

# Collects all the .nbib files in the wd and outputs them as dataframes
fileNames <- Sys.glob("*.nbib")
for (fileName in fileNames) {
  sample <- litsearchr::import_results(file=fileName)
  assign(paste0(tools::file_path_sans_ext(fileName)),sample)
}

```




## 2. Use litsearchr to collate keywords



We can have a look at the keywords, the function takes the dataset, 

```{r get_keywords}
S1_keywords <-term_extractor(naive_results,1,3)
S1_keywords
```

## Collating search title content

A bit more to do here as titles can contain many "stopwords" that are not informative to the topic of the article. I have begun to build a tentative stopword list at SR_stopwords.txt 

```{r create_stops}

SR_stopwords <- read_lines("SR_stopwords.txt")
all_stopwords <- c(get_stopwords("English"), SR_stopwords)

```

```{r get_best_titles}
S1_titles<- get_best_titles(naive_results)
S1_titles
```

We can combine these useful title terms with keywords, removing duplicates:
```{r combined_terms}
S1_terms <- unique(c(S1_keywords, S1_titles))
```


### Network analysis of content

We can create and visualise our content: 
```{r testing_network_creation}
S1_network <- create_the_network(naive_results,S1_terms)
print_the_network(S1_network)
```

We can now visualise this:


And find the strongest links in the network (note later entries have a stronger link):

```{r network_strengths}
S1_net_strengths <- strengths_of_network(S1_network)
```


This can then be plotted against changepoints (where the network strength shifs, a bit like an eigenvalue)


```{r network_cutoffs}
S1_net_outputs<- find_network_cutoffs(S1_net_strengths, S1_network)
S1_cutoff <- unlist(S1_net_outputs[1])
S1_net_outputs[2]
```

By selecting one of these changepoints the set of title-derived keywords can be reduced down:


```{r}
S1_net_redux <- reduce_graph(S1_network, S1_cutoff[1]) # tweak this number to change the cutoff option
S1_selected_terms <- get_keywords(S1_net_redux)
S1_selected_terms
```

### find some way of connecting this back with the keywords
The Tudge walkthrough doesn't discuss this. But it seems that we have  information from the keywords that hasn't been involved in the network analysis, but we don't want to discard. Lacking expertise, the simplest thing would be to combine these with the title-derived selected terms just produced. (Also add in some starred terms from the original approach).
```{r longlist}


longlist <- unique(c(keywords, selected_terms))

extra_terms <- c(
  "pain*",
  "cognit*",
  "screen*"
)

longlist <-c(longlist, extra_terms)
longlist

```




## Grouping with litsearchr

The recommendation is to do this by hand - pick out the terms from the list and organise them under your themes.

```{r make_terms_shortlists}
grouped_terms <-list(
  pain=longlist[c(12,13,14,37,44,45,50,54,55,62,63,99)],
 cognition=longlist[c(15:20,24,51,96,100)],
  screen=longlist[c(7,82,93,101)]
)
grouped_terms

```
```{r temptable}
lapply(grouped_terms, write, "test.txt", append=TRUE, ncolumns=1000)
```




```{r write_shortlist, eval=FALSE, include=TRUE}

# record this search into a text file
write_search(
  grouped_terms,
  languages="English",
  exactphrase=TRUE,
  stemming=FALSE, # DECISION: stem or not stem?
  closure="left",
  writesearch=TRUE
)

cat(read_file("search-inEnglish.txt"))
```




\(\("chronic migraine" OR "chronic musculoskeletal pain" OR "chronic pain" OR fibromyalgia OR knee OR "low back pain" OR migraine OR "neuropathic pain" OR nociception OR pain\) AND \(cognition OR cognitive OR dementia OR "mild cognitive impairment"\) AND \(screening\)\)



# Population search terms
Not sure about this: do we need to specify Adult or just use in exclusion criteria?


```{r preview, include=FALSE}

input_file <- "toolkit_screens.csv"
x <- readr::spec_csv(input_file) # good practice to peek before reading in
x

```

```{r load_file, include=FALSE}
cog_screens <- read_csv(input_file
                     )
```






# Pain search terms


## DRAW SOMETHING FROM LITSEARCHR
### Add further terms



# Cognitive screen search terms

```{r make_abbreviation_vector, include=FALSE}




a <- cog_screens  %>% 
  tidyr::drop_na(abbreviation_alt) %>%
  dplyr::pull(abbreviation_alt)

b <- cog_screens  %>% 
  tidyr::drop_na(abbreviation) %>%
  dplyr::pull(abbreviation)

all_abbrevs <-c(a,b)

all_names <- cog_screens  %>% 
  tidyr::drop_na(test_name) %>%
  dplyr::pull(test_name)
       

```







## Raw search terms


Based on all the cognitive screens in the .csv file, we would need to search for these test names and referents.

```{r text_list, include=TRUE}


screen_all_names<- str_flatten(all_names,"\" OR \"")
screen_abbreviations<- str_flatten(all_abbrevs,"\" OR \"")
screen_referents <- str_c("\"", screen_all_names, "\" OR \"", screen_abbreviations, "\"")
 writeLines(screen_referents)

```
In other words:

`r screen_referents`


*Note:* in fact some of the screeners names will need to be amended with wildcards.

## Putting search terms into readable contexts

### EBSCO Host

```{r make_ebsco_friendly}
s_screen_title <-  str_c("TI (",screen_referents,")")
s_screen_abstract <-  str_c("AB (",screen_referents,")")
  s_screen_testmeasures  <-  str_c("TM (",screen_referents,")")

```


# Finalise everything

```{r write_shortlist2, eval=FALSE, include=TRUE}

# record this search into a text file
final_search <- write_search(
  TO_DEFINE,
  languages="English",
  exactphrase=TRUE,
  stemming=FALSE, # DECISION: stem or not stem?
  closure="left",
  writesearch=FALSE
)

final_search
```

### Feeding this back in to pubmed

We get a new search, which we save in as new_results:

```{r import_new}
new_results <- import_results(file="new_pubmed.nbib")
```


```{r find_discrepancies}
naive_results %>%
  mutate(in_new_results=title %in% new_results[, "title"]) ->
  naive_results

excluded_articles <- naive_results %>%
  filter(!in_new_results) %>%
  select(title, keywords)

```

```{r write_discrepancies, eval=FALSE, include=TRUE}
 write.csv(excluded_articles, file = "excluded_articles.csv")
```




```{r checking_importants}
important_titles <- c(
  "Screening for pain in patients with cognitive and communication difficulties: evaluation of the SPIN-screen",
  "Pain and the Montreal Cognitive Assessment (MoCA) in Aging",
  "Disruption of cognitive function in Fibromyalgia Syndrome",
  "Cognitive Function Impairment in Patients with Neuropathic Pain Under Standard Conditions of Care",
  "Validity and reliability of the clock drawing test as a screening tool for cognitive impairment in patients with fibromyalgia",
  "Tales of the boogeyman"
)

data.frame(check_recall(important_titles, new_results[, "title"]))
```



